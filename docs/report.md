# üìë Informe Final del Proyecto

## 1. Introducci√≥n
Este proyecto aborda el problema de **clasificaci√≥n de textos** a partir de t√≠tulos y res√∫menes de art√≠culos.  
El objetivo principal es comparar diferentes modelos de *machine learning* para determinar cu√°l ofrece el mejor desempe√±o, tomando como m√©trica principal el **F1 Score ponderado**.

---

## 2. Metodolog√≠a

### 2.1 Conjunto de datos
- **Fuente:** [challenge_data-18-ago.csv]  
- **N√∫mero de instancias:** 3565 documentos  
- **N√∫mero de clases:** 4 categor√≠as  
- **Preprocesamiento:**  
  - No contaba con datos faltantes o nulos.
  - No contaba con datos duplicados.
  - No contenia caracteres especiales, puesto que estos no existen en el idioma ingl√©s.
  - Se convirti√≥ todo el texto a min√∫sculas.
  - Las etiquetas fueron codificadas usando `MultiLabelBinarizer`.
  - Para la vectorizacion de las palabras se us√≥ **TF-IDF**, con un m√°ximo de 5000 caracter√≠sticas y los stopwords prederteminados para el idioma ingl√©s.

### 2.2 Modelos entrenados
- **Logistic Regression (OneVsRestClassifier)**  
  - Hiperpar√°metros: `max_iter=1000`, `class_weight='balanced'`  
- **SVM (LinearSVC, OneVsRestClassifier)**  
  - Hiperpar√°metros: `C=1.0`, `max_iter=1000`, `class_weight='balanced'`  

---

## 3. Experimentos y Resultados

### 3.1 M√©tricas de evaluaci√≥n
Se utilizaron las siguientes m√©tricas:  
- Precisi√≥n (Precision)  
- Exhaustividad (Recall)  
- F1-Score ponderado (**m√©trica principal**)  
- Matriz de confusi√≥n  

### 3.2 Resultados comparativos

| Modelo                | Precision (Weighted) | Recall (Weighted) | F1-Score (Weighted) |
|------------------------|----------------------|-------------------|---------------------|
| Logistic Regression    | 0.90                 | 0.85              | **0.87**            |
| SVM (LinearSVC)        | 0.91                 | 0.86              | **0.88**            |

### 3.3 Visualizaciones
**Comparaci√≥n del F1 Score ponderado:**  
![F1 Weighted Comparison](../data/metrics/weighted_f1_score_comparison.png)

**Matriz de confusi√≥n:**  
![Confusion Matrices](../data/metrics/confusion_matrices.png)

---

## 4. Discusi√≥n y Reflexiones
- La **Regresi√≥n Log√≠stica** fue probada sin clases balanceadas y aunque la precision fue alta, los resultados obtenidos para recall fueron bastante bajos, lo que indica que el modelo no es capaz de identificar correctamente las clases minoritarias. Al probarse con clases balanceadas, se obtuvo un mejor desempe√±o en todas las m√©tricas.
- El **SVM** mostr√≥ un rendimiento consistente al ser probado con y sin clases balanceadas, las diferencias son minimas en las metricas.  
- El uso de **TF-IDF** permiti√≥ una representaci√≥n efectiva, pero carece de sem√°ntica profunda.  

---

## 5. Conclusiones
- El modelo con mejor desempe√±o para identificar clases minoritarias fue: **[SVM]**.  
- El **F1 Score ponderado** confirma la robustez del modelo frente a clases desbalanceadas.   

---

